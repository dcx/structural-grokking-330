nlprun -n bllip-lg-16layer-1.0-l8-a0.25-ce-s -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-1.0-l8-a0.25-ce-s.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-1.0-l8-a0.25-ce-s/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 50000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 10 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --layer_id 8 --sci_heads 0.25 --ce'

nlprun -n bllip-lg-16layer-1.0-l8-a0.25-ce-cky -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-1.0-l8-a0.25-ce-cky.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-1.0-l8-a0.25-ce-cky/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 50000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 10 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --layer_id 8 --sci_heads 0.25 --ce --cky --cky_dec --margin 1'

nlprun -n bllip-lg-16layer-1.0-l8-a0.25-ce-cky -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-1.0-l8-a0.25-ce-cky.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-1.0-l8-a0.25-ce-cky/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 50000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 10 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --layer_id 8 --sci_heads 0.25 --ce --cky --cky_dec --margin 1'

nlprun -n bllip-lg-16layer-1.0-l4-a0.125-ce-cky-bidir -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-1.0-l4-a0.125-ce-cky-bidir.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-1.0-l4-a0.125-ce-cky-bidir/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 50000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 10 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 4 --sci_heads 0.125 --ce --cky --cky_dec'

nlprun -n bllip-lg-16layer-1.0-l12-a0.25-ce-bidir -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-1.0-l12-a0.25-ce-bidir.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-1.0-l12-a0.25-ce-bidir/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 60000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 32 --accum_steps 5 --start_lr 1e-4 --end_lr 6e-5 --relative True --use_amp --regularize --regularizer_rel_wt_init 1.0 --regularizer_steps 10 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 12 --sci_heads 0.25 --ce'

nlprun -n bllip-lg-16layer-1.0-l12-a0.25-ce-bidir-randomize -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-1.0-l12-a0.25-ce-bidir-randomize.txt --mail-user ananjan -r 40G -d a6000 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-1.0-l12-a0.25-ce-bidir-randomize/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 60000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 32 --accum_steps 5 --start_lr 1e-4 --end_lr 6e-5 --relative True --use_amp --randomize --regularize --regularizer_rel_wt_init 1.0 --regularizer_steps 10 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 12 --sci_heads 0.25 --ce'

python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 60000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 32 --accum_steps 5 --start_lr 2e-4 --end_lr 6e-5 --relative True --use_amp --regularize --regularizer_rel_wt_init 1.0 --regularizer_steps 10 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 12 --sci_heads 0.25 --ce

nlprun -n bllip-lg-16layer-1.0-l12-a0.25-ce-bidir-0.1p -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-1.0-l12-a0.25-ce-bidir-0.1p.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-1.0-l12-a0.25-ce-bidir-0.1p/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 100000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 32 --accum_steps 5 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 10 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 12 --sci_heads 0.25 --ce --parse_portion 0.1'

nlprun -n bllip-lg-16layer-1.0-l12-a0.25-ce-bidir-0.01p -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-1.0-l12-a0.25-ce-bidir-0.01p.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-1.0-l12-a0.25-ce-bidir-0.01p/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 100000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 32 --accum_steps 5 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 10 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 12 --sci_heads 0.25 --ce --parse_portion 0.01'

nlprun -n bllip-lg-16layer-1.0-l8-a0.25-ce-20s100-bidir -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-1.0-l8-a0.25-ce-20s100-bidir.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-1.0-l8-a0.25-ce-20s100-bidir/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 50000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 10 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --reg_single --reg_sample_num 20 --reg_sample_len 100 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 8 --sci_heads 0.25 --ce'

nlprun -n bllip-lg-16layer-1.0-l8-a0.25-ce-cky-bidir -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-1.0-l8-a0.25-ce-cky-bidir.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-1.0-l8-a0.25-ce-cky-bidir/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 50000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 10 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 8 --sci_heads 0.25 --ce --cky --cky_dec'

python train_transformers.py --dataset=ptb --save_dir /nlp/scr/ananjan/ptb-16layer-1.0-l8-a0.25-ce-bidir/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 50000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 10 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 8 --sci_heads 0.25 --ce

python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-1.0-l8-a0.25-mixture-ce-bidir/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 50000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 10 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --mixture --layer_id 8 --sci_heads 0.25 --ce

nlprun -n bllip-md-16layer-1.0-l8-a0.25-mixture-ce-bidir -g 1 -a tree-reg-2 -o logs/bllip-md-16layer-1.0-l8-a0.25-mixture-ce-bidir.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-md --save_dir /nlp/scr/ananjan/bllip-md-16layer-1.0-l8-a0.25-mixture-ce-bidir/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 50000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 10 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --mixture --layer_id 8 --sci_heads 0.25 --ce --cky_dec'

nlprun -n bllip-lg-16layer-1.0-l8-a0.25-mixture-ce-bidir -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-1.0-l8-a0.25-mixture-ce-bidir.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-1.0-l8-a0.25-mixture-ce-bidir/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 50000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 10 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --mixture --layer_id 8 --sci_heads 0.25 --ce --cky_dec'

nlprun -n bllip-lg-16layer-1.0-l8-a0.25-mixture-cosine-ce-bidir -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-1.0-l8-a0.25-mixture-cosine-ce-bidir.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-1.0-l8-a0.25-mixture-cosine-ce-bidir/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 50000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 10 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --orth_comp --mixture --layer_id 8 --sci_heads 0.25 --ce --cky_dec'

nlprun -n bllip-lg-16layer-1.0-l8-a0.25-mixture-margin1-bidir -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-1.0-l8-a0.25-mixture-margin1-bidir.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-1.0-l8-a0.25-mixture-margin1-bidir/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 50000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 10 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --mixture --layer_id 8 --sci_heads 0.25 --margin 1 --cky_dec'

nlprun -n ptb-16layer-1.0-l8-a0.25-ce-cky-bidir -g 1 -a tree-reg-2 -o logs/ptb-16layer-1.0-l8-a0.25-ce-cky-bidir.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=ptb --save_dir /nlp/scr/ananjan/ptb-16layer-1.0-l8-a0.25-ce-cky-bidir/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 50000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 500 --batch_size 12 --accum_steps 10 --lr 1e-4 --relative True --regularize True --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 8 --sci_heads 0.25 --ce --cky --cky_dec'

python eval_utils/eval_ptb.py --model_load_path /nlp/scr/ananjan/bllip-lg-16layer-1.0-l12-a0.25-ce-bidir/state.pt --relative --layer_id 12 --sci_heads 0.25 --use_orthogonal --orth_bidir --orth_single

python train_transformers.py --dataset=bllip-md --save_dir /nlp/scr/ananjan/bllip-md-test/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 50000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 16 --accum_steps 5 --start_lr 1e-4 --relative True --regularize --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 8 --sci_heads 0.25 --ce --hf --hf_model_name princeton-nlp/Sheared-LLaMA-1.3B

nlprun -n bllip-lg-16layer-base -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-base.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-base/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 100000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 32 --accum_steps 5 --lr 1e-4 --relative True --use_amp'

nlprun -n bllip-lg-16layer-base-pack1024 -g 1 -a tree-reg-2 -o logs/bllip-lg-base-pack1024.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-base-pack1024/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 10000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 100 --pack --max_seq_len 1024 --batch_size 16 --accum_steps 10 --lr 1e-4 --relative True'

nlprun -n bllip-lg-16layer-base-relative-pack512 -g 1 -a tree-reg-2 -o logs/bllip-lg-base-relative-pack512.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-base-relative-pack512/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 10000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 100 --pack --max_seq_len 512 --batch_size 16 --accum_steps 10 --lr 1e-4 --relative True --use_amp'

nlprun -n bllip-lg-16layer-base-rotary-pack512 -g 1 -a tree-reg-2 -o logs/bllip-lg-base-rotary-pack512.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-base-rotary-pack512/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 10000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 100 --pack --max_seq_len 512 --batch_size 16 --accum_steps 10 --lr 1e-4 --rotary True --causal_only --use_amp'

nlprun -n bllip-lg-16layer-relative-pack512-1.0-l12-a0.25-ce-bidir -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-relative-pack512-1.0-l12-a0.25-ce-bidir.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-relative-pack512-1.0-l12-a0.25-ce-bidir/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 10000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 100 --pack --max_seq_len 512 --batch_size 16 --accum_steps 5 --start_lr 1e-4 --end_lr 6e-5 --relative True --use_amp --regularize --regularizer_rel_wt_init 1.0 --regularizer_steps 10 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 12 --sci_heads 0.25 --ce'

nlprun -n bllip-lg-16layer-rotary-pack512-1.0-l12-a0.25-ce-bidir -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-rotary-pack512-1.0-l12-a0.25-ce-bidir.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-rotary-pack512-1.0-l12-a0.25-ce-bidir/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 10000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 100 --pack --max_seq_len 512 --batch_size 16 --accum_steps 10 --lr 1e-4 --rotary True --causal_only --use_amp --regularize --regularizer_rel_wt_init 1.0 --regularizer_steps 10 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 12 --sci_heads 0.25 --ce'

nlprun -n bllip-lg-16layer-rotary-1.0-l12-a0.25-ce-bidir -g 1 -a tree-reg-2 -o logs/bllip-lg-16layer-rotary-1.0-l12-a0.25-ce-bidir.txt --mail-user ananjan -r 40G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-16layer-rotary-1.0-l12-a0.25-ce-bidir/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 100000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 16 --accum_steps 10 --start_lr 1e-4 --end_lr 6e-5 --rotary True --use_amp --regularize --regularizer_rel_wt_init 1.0 --regularizer_steps 10 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 12 --sci_heads 0.25 --ce'

python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/bllip-lg-pack1024-test/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 10000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 100 --pack --max_seq_len 1024 --batch_size 8 --accum_steps 10 --lr 1e-4 --rotary True --causal_only --use_amp --regularize --regularizer_rel_wt_init 1.0 --regularizer_steps 10 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 12 --sci_heads 0.25 --ce

nlprun -n llama-bllip-lg-1.0-l12-a0.25-ce-bidir -g 1 -a tree-reg-2 -o logs/llama-bllip-lg-1.0-l12-a0.25-ce-bidir.txt --mail-user ananjan -r 80G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/llama-bllip-lg-1.0-l12-a0.25-ce-bidir/ --seed 10 --callback --lm True --max_train_steps 20000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 16 --accum_steps 5 --start_lr 1e-5 --relative True --regularize --regularizer_rel_wt_init 1.0 --regularizer_steps 10 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 12 --sci_heads 0.25 --ce --hf --hf_model_name princeton-nlp/Sheared-LLaMA-1.3B'

nlprun -n llama-bllip-lg-1.0-l18-a0.25-ce-bidir -g 1 -a tree-reg-2 -o logs/llama-bllip-lg-1.0-l18-a0.25-ce-bidir.txt --mail-user ananjan -r 80G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/llama-bllip-lg-1.0-l18-a0.25-ce-bidir/ --seed 10 --callback --lm True --max_train_steps 10000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 25 --start_lr 1e-5 --relative True --regularize --regularizer_rel_wt_init 1.0 --regularizer_steps 10 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 18 --sci_heads 0.25 --ce --hf --hf_model_name princeton-nlp/Sheared-LLaMA-1.3B'

nlprun -n llama-bllip-lg-base -g 1 -a tree-reg-2 -o logs/llama-bllip-lg-base.txt --mail-user ananjan -r 80G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/llama-bllip-lg-base/ --seed 10 --callback --lm True --max_train_steps 10000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 25 --start_lr 1e-5 --relative True --regularize --regularizer_rel_wt_init 0.0 --regularizer_steps 10 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --orth_bidir --layer_id 12 --sci_heads 0.25 --ce --hf --hf_model_name princeton-nlp/Sheared-LLaMA-1.3B'

nlprun -n llama-bllip-lg-16layer-1.0-l12-a0.25-ce -g 1 -a tree-reg-2 -o logs/llama-bllip-lg-16layer-1.0-l12-a0.25-ce.txt --mail-user ananjan -r 80G -d a6000 -p high 'python train_transformers.py --dataset=bllip-lg --save_dir /nlp/scr/ananjan/llama-bllip-lg-16layer-1.0-l12-a0.25-ce/ --encoder_n_layers 16 --seed 10 --callback --lm True --max_train_steps 10000 --wandb_user ananjan --save_model --save_interval 0 --eval_every 1000 --batch_size 12 --accum_steps 25 --start_lr 1e-4 --relative True --regularize --regularizer_rel_wt_init 1.0 --regularizer_steps 5 --embedding_dropout 0.1 --output_dropout 0.1 --use_gold --enforce_gold --use_orthogonal --orth_single --layer_id 12 --sci_heads 0.25 --ce --hf --hf_model_name princeton-nlp/Sheared-LLaMA-1.3B'

python eval_utils/eval_surprisal.py --model_load_path /nlp/scr/ananjan/llama-bllip-lg-base/state.pt --relative --layer_id 20 --sci_heads 0.25 --use_orthogonal --orth_bidir --orth_single --hf --hf_model_name princeton-nlp/Sheared-LLaMA-1.3B